{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy-quaternion in /usr/local/lib/python2.7/dist-packages\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install numpy-quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/quaternion/numba_wrapper.py:29: UserWarning: \n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Could not import from either numbapro or numba.\n",
      "This means that the code will run MUCH more slowly.\n",
      "You probably REALLY want to install numba / numbapro.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "  warnings.warn(warning_text)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import quaternion\n",
    "\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from fast_image import Image\n",
    "from color import Color\n",
    "from feat_2d import Circle2D\n",
    "from feat_3d import Sphere3D\n",
    "from searchers import do_linear_search, do_binary_search\n",
    "from optimizers import findPose\n",
    "from ros import RosHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "# Configure Jupyter to auto-reload constituent libraries when reasonable\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -rospy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Useful resources\n",
    "\n",
    "[OpenCV tutorial](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html#playing-video-from-file)\n",
    "\n",
    "![](http://wiki.ros.org/image_pipeline/CameraInfo?action=AttachFile&do=get&target=CameraCoords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define hardcoded map for testing tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define colors\n",
    "green = Color(minimum=(30, 50, 100), maximum=(60, 255, 255))\n",
    "orange = Color(minimum=(5, 120, 130), maximum=(30, 255, 255))\n",
    "blue = Color(minimum=(90, 60, 90), maximum=(150, 255, 255))\n",
    "black = Color(minimum=(0, 0, 0), maximum=(255, 210, 150))\n",
    "\n",
    "# Define 3D features\n",
    "greenSphere = Sphere3D((.55/2,.45/2,0), .106, green)\n",
    "orangeSphere = Sphere3D((-.55/2,.45/2,0), .106, orange)\n",
    "blueSphere = Sphere3D((.55/2,-.45/2,0), .106, blue)\n",
    "blackSphere = Sphere3D((-.55/2,-.45/2,0), .106, black)\n",
    "\n",
    "# Define initial condition\n",
    "startPos = np.array([0, 0, -1.5])\n",
    "startQuat = np.quaternion(1, 0, 0 ,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ROS functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ros = RosHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Capture and handle video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FILE = '../test_data/unstabilized.mp4'\n",
    "cv2.namedWindow('raw_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 evaluations needed, final error [  1.45482061e+00   1.86975397e-01  -5.96127875e-01   1.11654353e-01\n",
      "  -1.61669463e+00   6.02760075e-01   8.01122917e-01  -9.99450086e-01\n",
      "  -2.54850687e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      "18.1ms reading and drawing image, 20.2ms (49fps) processing, 148 pixels accessed\n",
      "\n",
      "End of video file reached\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def handleFrame(frame, features, verbose=False):\n",
    "    image = Image(frame)\n",
    "\n",
    "    for f in features:\n",
    "        f.refine(image, verbose=verbose)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def main():\n",
    "    pos = startPos\n",
    "    quat = startQuat\n",
    "#     pos = np.array([-1, 0, -1])\n",
    "#     quat = np.quaternion(1,0,.5,0).normalized()\n",
    "    spheres = deepcopy([greenSphere, orangeSphere, blueSphere, blackSphere])\n",
    "    i=0\n",
    "    while cap.isOpened():\n",
    "        verbose = i%50 == 0\n",
    "        if verbose:\n",
    "            clear_output()\n",
    "        i += 1\n",
    "        \n",
    "        startTime = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        readTime = time.time()\n",
    "\n",
    "        if frame is None or len(frame) <= 0:\n",
    "            print \"End of video file reached\"\n",
    "            break\n",
    "\n",
    "        # Do work here\n",
    "        features = [sphere.project(pos, quaternion.as_rotation_matrix(quat))\n",
    "                   for sphere in spheres]\n",
    "        startFeats = deepcopy(features)\n",
    "        \n",
    "        image = handleFrame(frame, features, verbose=verbose)\n",
    "        \n",
    "        pos, quat = findPose(spheres, features, pos, quat, verbose=verbose)\n",
    "#         quat = np.quaternion(1,0,0,0)\n",
    "            \n",
    "        finishTime = time.time()\n",
    "        \n",
    "        ros.publish_pose(pos, quat)\n",
    "\n",
    "        for f in features:\n",
    "            f.draw(frame)\n",
    "            \n",
    "        image.draw(frame)\n",
    "        scaled = cv2.resize(frame, dsize=None, fx=0.5, fy=0.5)\n",
    "        cv2.imshow('raw_frame', scaled)\n",
    "        \n",
    "        drawnTime = time.time()\n",
    "\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        if verbose:\n",
    "            processingTime = (finishTime-readTime)\n",
    "            print \"{0:.1f}ms reading and drawing image, {1:.1f}ms ({3}fps) processing, {2} pixels accessed\\n\".format(\n",
    "                (readTime-startTime + drawnTime-finishTime)*1000, \n",
    "                processingTime*1000, \n",
    "                len(image.pixelsAccessed),\n",
    "                int(1/processingTime))\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Profile things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'greenSphere' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ff7de7d60d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m greenSmall = greenSphere.project(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartPos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     orientation=quaternion.as_rotation_matrix(startQuat))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'greenSphere' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "greenSmall = greenSphere.project(\n",
    "    pos=startPos, \n",
    "    orientation=quaternion.as_rotation_matrix(startQuat))\n",
    "import scipy.optimize\n",
    "\n",
    "def bench():\n",
    "    features = deepcopy([greenSmall])\n",
    "    for _ in range(60):\n",
    "        ret, frame = cap.read()\n",
    "        handleFrame(frame, features)\n",
    "    \n",
    "%lprun -r -f do_binary_search bench()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
