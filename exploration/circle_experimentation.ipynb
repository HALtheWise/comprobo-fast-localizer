{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy-quaternion in /usr/local/lib/python2.7/dist-packages\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install numpy-quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/quaternion/numba_wrapper.py:29: UserWarning: \n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Could not import from either numbapro or numba.\n",
      "This means that the code will run MUCH more slowly.\n",
      "You probably REALLY want to install numba / numbapro.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "  warnings.warn(warning_text)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import quaternion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "from camera_calibration_parsers import readCalibration\n",
    "import image_geometry\n",
    "\n",
    "from tf import transformations\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "\n",
    "import rospy\n",
    "import tf\n",
    "from geometry_msgs.msg import PoseStamped, Pose, Vector3, Quaternion\n",
    "from std_msgs.msg import Header\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from client_mk1.fast_image import Image\n",
    "from client_mk1.color import Color\n",
    "from client_mk1.feat_2d import Circle2D\n",
    "from client_mk1.feat_3d import Sphere3D\n",
    "from client_mk1.searchers import do_linear_search, do_binary_search\n",
    "from client_mk1.optimizers import findPose\n",
    "from client_mk1.ros import ros_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "# Configure Jupyter to auto-reload constituent libraries when reasonable\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -rospy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Useful resources\n",
    "\n",
    "[OpenCV tutorial](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html#playing-video-from-file)\n",
    "\n",
    "![](http://wiki.ros.org/image_pipeline/CameraInfo?action=AttachFile&do=get&target=CameraCoords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define hardcoded map for testing tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "green = Color(minimum=(30, 50, 100), maximum=(60, 255, 255))\n",
    "orange = Color(minimum=(5, 120, 130), maximum=(30, 255, 255))\n",
    "blue = Color(minimum=(90, 60, 90), maximum=(150, 255, 255))\n",
    "black = Color(minimum=(0, 0, 0), maximum=(255, 210, 150))\n",
    "\n",
    "# greenCircle = Circle2D((1920/2, 1080/2), 400, green)\n",
    "# orangeCircle = Circle2D((1920/2, 1080/2), 400, orange)\n",
    "\n",
    "greenSmall = Circle2D((1100, 700), 130, green)\n",
    "orangeSmall = Circle2D((600, 700), 130, orange)\n",
    "\n",
    "greenSphere = Sphere3D((.55/2,.45/2,0), .106, green)\n",
    "orangeSphere = Sphere3D((-.55/2,.45/2,0), .106, orange)\n",
    "blueSphere = Sphere3D((.55/2,-.45/2,0), .106, blue)\n",
    "blackSphere = Sphere3D((-.55/2,-.45/2,0), .106, black)\n",
    "\n",
    "\n",
    "startPos = np.array([0, 0, -1.5])\n",
    "startQuat = np.quaternion(1, 0, 0 ,0)\n",
    "\n",
    "\n",
    "greenCircle = greenSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "orangeCircle = orangeSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "blueCircle = blueSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "blackCircle = blackSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ROS functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ros = ros_handler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Capture and handle video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FILE = '../test_data/unstabilized.mp4'\n",
    "cv2.namedWindow('raw_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 evaluations needed, final error [  1.45482061e+00   1.86975397e-01  -5.96127875e-01   1.11654353e-01\n",
      "  -1.61669463e+00   6.02760075e-01   8.01122917e-01  -9.99450086e-01\n",
      "  -2.54850687e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      "12.5ms reading and drawing image, 18.5ms (54fps) processing, 148 pixels accessed\n",
      "\n",
      "End of video file reached\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def handleFrame(frame, features, verbose=False):\n",
    "    image = Image(frame)\n",
    "\n",
    "    for f in features:\n",
    "        f.refine(image, verbose=verbose)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def main():\n",
    "    pos = startPos\n",
    "    quat = startQuat\n",
    "#     pos = np.array([-1, 0, -1])\n",
    "#     quat = np.quaternion(1,0,.5,0).normalized()\n",
    "    spheres = deepcopy([greenSphere, orangeSphere, blueSphere, blackSphere])\n",
    "    i=0\n",
    "    while cap.isOpened():\n",
    "        verbose = i%50 == 0\n",
    "        if verbose:\n",
    "            clear_output()\n",
    "        i += 1\n",
    "        \n",
    "        startTime = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        readTime = time.time()\n",
    "\n",
    "        if frame is None or len(frame) <= 0:\n",
    "            print \"End of video file reached\"\n",
    "            break\n",
    "\n",
    "        # Do work here\n",
    "        features = [sphere.project(pos, quaternion.as_rotation_matrix(quat))\n",
    "                   for sphere in spheres]\n",
    "        startFeats = deepcopy(features)\n",
    "        \n",
    "        image = handleFrame(frame, features, verbose=verbose)\n",
    "        \n",
    "        pos, quat = findPose(spheres, features, pos, quat, verbose=verbose)\n",
    "#         quat = np.quaternion(1,0,0,0)\n",
    "            \n",
    "        finishTime = time.time()\n",
    "        \n",
    "        ros.publish_pose(pos, quat)\n",
    "\n",
    "        for f in features:\n",
    "            f.draw(frame)\n",
    "            \n",
    "        image.draw(frame)\n",
    "        scaled = cv2.resize(frame, dsize=None, fx=0.5, fy=0.5)\n",
    "        cv2.imshow('raw_frame', scaled)\n",
    "        \n",
    "        drawnTime = time.time()\n",
    "\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        if verbose:\n",
    "            processingTime = (finishTime-readTime)\n",
    "            print \"{0:.1f}ms reading and drawing image, {1:.1f}ms ({3}fps) processing, {2} pixels accessed\\n\".format(\n",
    "                (readTime-startTime + drawnTime-finishTime)*1000, \n",
    "                processingTime*1000, \n",
    "                len(image.pixelsAccessed),\n",
    "                int(1/processingTime))\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Profile things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<line_profiler.LineProfiler at 0x7fd813509b48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def bench():\n",
    "    features = deepcopy([greenSmall])\n",
    "    for _ in range(60):\n",
    "        ret, frame = cap.read()\n",
    "        handleFrame(frame, features)\n",
    "    \n",
    "%lprun -r -f do_binary_search bench()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
