{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy-quaternion in /usr/local/lib/python2.7/dist-packages\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install numpy-quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quaternion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "from camera_calibration_parsers import readCalibration\n",
    "import image_geometry\n",
    "\n",
    "from tf import transformations\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "\n",
    "import rospy\n",
    "import tf\n",
    "from geometry_msgs.msg import PoseStamped, Pose, Vector3, Quaternion\n",
    "from std_msgs.msg import Header\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from client_mk1.fast_image import Image\n",
    "from client_mk1.color import Color\n",
    "from client_mk1.feat_2d import Circle2D\n",
    "from client_mk1.searchers import do_linear_search, do_binary_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -rospy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rospy.init_node('fast_localization_client')\n",
    "try:\n",
    "    pose_pub.unregister()\n",
    "except:\n",
    "    pass\n",
    "pose_pub = rospy.Publisher('/pose', PoseStamped, queue_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Useful resources\n",
    "\n",
    "[OpenCV tutorial](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html#playing-video-from-file)\n",
    "\n",
    "![](http://wiki.ros.org/image_pipeline/CameraInfo?action=AttachFile&do=get&target=CameraCoords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load camera configuration info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_, calibration = readCalibration(\"../calibration/unstabilized_pixel.yaml\")\n",
    "camera = image_geometry.PinholeCameraModel()\n",
    "camera.fromCameraInfo(calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define types for 3D features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Sphere3D(object):\n",
    "    \"\"\"\n",
    "    Sphere3D represents a sphere known to exist in 3D map-space.\n",
    "    \"\"\"\n",
    "    def __init__(self, center, radius, colorRange):\n",
    "        self.center = np.array(center)\n",
    "        self.radius = radius\n",
    "        self.color = colorRange\n",
    "\n",
    "        # TODO: this should be a scalar with more reasonable behavior\n",
    "        self.confidence = True\n",
    "        \n",
    "    def project(self, pos, orientation):\n",
    "        \"\"\"\n",
    "        Returns the coordinates of the given point in the camera image\n",
    "        \"\"\"\n",
    "        relative_center = self.center - pos\n",
    "        relative_center = np.dot(np.transpose(orientation), relative_center)\n",
    "        \n",
    "        center2D = camera.project3dToPixel(relative_center)\n",
    "        x, y, w = relative_center\n",
    "        radius2D = camera.fx() * self.radius / w\n",
    "        \n",
    "        return Circle2D(center2D, radius2D, self.color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Circle(center=[ 1255.15801843   766.60709505], radius=102.317940611)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = greenSphere\n",
    "s.project(startPos,np.identity(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define hardcoded map for testing tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "green = Color(minimum=(30, 50, 100), maximum=(60, 255, 255))\n",
    "orange = Color(minimum=(5, 120, 130), maximum=(30, 255, 255))\n",
    "blue = Color(minimum=(90, 60, 90), maximum=(150, 255, 255))\n",
    "black = Color(minimum=(0, 0, 0), maximum=(255, 210, 150))\n",
    "\n",
    "# greenCircle = Circle2D((1920/2, 1080/2), 400, green)\n",
    "# orangeCircle = Circle2D((1920/2, 1080/2), 400, orange)\n",
    "\n",
    "greenSmall = Circle2D((1100, 700), 130, green)\n",
    "orangeSmall = Circle2D((600, 700), 130, orange)\n",
    "\n",
    "greenSphere = Sphere3D((.55/2,.45/2,0), .106, green)\n",
    "orangeSphere = Sphere3D((-.55/2,.45/2,0), .106, orange)\n",
    "blueSphere = Sphere3D((.55/2,-.45/2,0), .106, blue)\n",
    "blackSphere = Sphere3D((-.55/2,-.45/2,0), .106, black)\n",
    "\n",
    "\n",
    "startPos = np.array([0, 0, -1.5])\n",
    "startQuat = np.quaternion(1, 0, 0 ,0)\n",
    "\n",
    "\n",
    "greenCircle = greenSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "orangeCircle = orangeSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "blueCircle = blueSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "blackCircle = blackSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Find 3D poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def packStateVector(pos, quat):\n",
    "    return np.array(tuple(pos)+tuple(quaternion.as_float_array(quat).ravel()))\n",
    "\n",
    "def unpackStateVector(state):\n",
    "    position = np.array(state[:3])\n",
    "    quat = np.quaternion(*state[3:])\n",
    "    return position, quat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.63450900e-02,  -1.88756500e-02,  -2.86295623e+00,\n",
       "         9.99615505e-01,  -1.00498077e-02,   5.05565336e-02,\n",
       "        -2.13947738e-03])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packStateVector([-0.07634509, -0.01887565, -2.86295623],np.quaternion(0.999615505058199, -0.0100498077476995, 0.0505565336078942, -0.00213947738153386))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def getDistFunc(spheres, foundCircles):\n",
    "    assert len(spheres) == len(foundCircles)\n",
    "    def distFunc(state):\n",
    "        position, quat = unpackStateVector(state)\n",
    "        \"\"\"\n",
    "        Takes a list of 7 numbers. The first three represent translational \n",
    "        position, and the last four form a rotation quaternion.\n",
    "        Returns a list of error values.\n",
    "        \"\"\"\n",
    "        matrix = quaternion.as_rotation_matrix(quat)\n",
    "        \n",
    "        errors = [c.distance(s.project(position, matrix).center)\n",
    "         for s, c in zip(spheres, foundCircles)\n",
    "                 if c.confidence == True]\n",
    "        \n",
    "        # Flatten the resulting 2-deep list\n",
    "        errors = [e for l in errors for e in l]\n",
    "        \n",
    "        # Note that scipy leastsq requires sufficient number of outputs,\n",
    "        # hacked here by feeding extra '0's\n",
    "        return errors + [quat.norm() - 1] + [0]*6\n",
    "        \n",
    "        \n",
    "    return distFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "quat = np.quaternion(1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[155.15801843333338,\n",
       " 66.607095050000112,\n",
       " 124.26304356666662,\n",
       " 66.607095050000112,\n",
       " 0.0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDistFunc([greenSphere, orangeSphere], [greenSmall, orangeSmall]\n",
    "           )(packStateVector(startPos, startQuat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: massive speed boosts should come from computing\n",
    "# the Jacobian more sensibly\n",
    "def findPose(spheres, circles, pos, quat, verbose=False):\n",
    "    p,cov,infodict,mesg,ier = optimize.leastsq(\n",
    "        getDistFunc(spheres, circles),\n",
    "        packStateVector(pos, quat),\n",
    "        xtol=5e-4,\n",
    "        full_output=1)\n",
    "    if verbose:\n",
    "        print '{} evaluations needed, final error {}'.format(infodict['nfev'], infodict['fvec'])\n",
    "    return unpackStateVector(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 evaluations needed, final error [  5.20966955e-06   6.28343139e-06  -7.97606367e-06   4.32512263e-06\n",
      "   2.09201323e-10   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.        , -1.59987096]),\n",
       " quaternion(0.998757418295752, -0.0179969907785118, 0.0461291306120982, -0.00564191813975188))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findPose([greenSphere, orangeSphere], [greenSmall, orangeSmall],\n",
    "         startPos, startQuat, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ROS functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def publish_pose(pos, quat):\n",
    "    # Convert the position and quaternion from OpenCV coordinates to ROS coordinates\n",
    "    pos = [pos[2], -pos[0], -pos[1]]\n",
    "    \n",
    "    quat = np.quaternion(0,0,0,1) * quat\n",
    "    quatList = quaternion.as_float_array(quat.normalized()).flatten()\n",
    "    quatList[1], quatList[2] = quatList[2], quatList[1]\n",
    "    \n",
    "    quatList[2] *= -1\n",
    "    quatList[3] *= -1\n",
    "    \n",
    "    # Pulish the result as a Pose in map frame\n",
    "    pose_pub.publish(PoseStamped(\n",
    "        header=Header(frame_id='map'),\n",
    "        pose=Pose(\n",
    "            position=Vector3(*pos), \n",
    "            orientation=Quaternion(*quatList))))\n",
    "    \n",
    "    # Publish the result as a transform from map frame to camera frame\n",
    "    br = tf.TransformBroadcaster()\n",
    "    br.sendTransform(pos,\n",
    "                     quatList,\n",
    "                     rospy.Time.now(),\n",
    "                     'camera',\n",
    "                     'map')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Capture and handle video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FILE = '../test_data/unstabilized_cardinal.mp4'\n",
    "cv2.namedWindow('raw_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 evaluations needed, final error [  1.19819547e+00   8.16461403e-01   8.01581127e-01  -1.73493383e-01\n",
      "  -1.69383093e+00   7.89161565e-01  -2.62837912e-01  -1.45885583e+00\n",
      "   2.10406327e-06   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      "33.8ms reading and drawing image, 35.2ms (28fps) processing, 148 pixels accessed\n",
      "\n",
      "End of video file reached\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def handleFrame(frame, features, verbose=False):\n",
    "    image = Image(frame)\n",
    "\n",
    "    for f in features:\n",
    "        f.refine(image, verbose=verbose)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def main():\n",
    "    pos = startPos\n",
    "    quat = startQuat\n",
    "#     pos = np.array([-1, 0, -1])\n",
    "#     quat = np.quaternion(1,0,.5,0).normalized()\n",
    "    spheres = deepcopy([greenSphere, orangeSphere, blueSphere, blackSphere])\n",
    "    i=0\n",
    "    while cap.isOpened():\n",
    "        verbose = i%50 == 0\n",
    "        if verbose:\n",
    "            clear_output()\n",
    "        i += 1\n",
    "        \n",
    "        startTime = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        readTime = time.time()\n",
    "\n",
    "        if frame is None or len(frame) <= 0:\n",
    "            print \"End of video file reached\"\n",
    "            break\n",
    "\n",
    "        # Do work here\n",
    "        features = [sphere.project(pos, quaternion.as_rotation_matrix(quat))\n",
    "                   for sphere in spheres]\n",
    "        startFeats = deepcopy(features)\n",
    "        \n",
    "        image = handleFrame(frame, features, verbose=verbose)\n",
    "        \n",
    "        pos, quat = findPose(spheres, features, pos, quat, verbose=verbose)\n",
    "#         quat = np.quaternion(1,0,0,0)\n",
    "            \n",
    "        finishTime = time.time()\n",
    "        \n",
    "        publish_pose(pos, quat)\n",
    "\n",
    "        for f in features:\n",
    "            f.draw(frame)\n",
    "            \n",
    "        image.draw(frame)\n",
    "        scaled = cv2.resize(frame, dsize=None, fx=0.5, fy=0.5)\n",
    "        cv2.imshow('raw_frame', scaled)\n",
    "        \n",
    "        drawnTime = time.time()\n",
    "\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        if verbose:\n",
    "            processingTime = (finishTime-readTime)\n",
    "            print \"{0:.1f}ms reading and drawing image, {1:.1f}ms ({3}fps) processing, {2} pixels accessed\\n\".format(\n",
    "                (readTime-startTime + drawnTime-finishTime)*1000, \n",
    "                processingTime*1000, \n",
    "                len(image.pixelsAccessed),\n",
    "                int(1/processingTime))\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Profile things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<line_profiler.LineProfiler at 0x7ff45552ef58>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def bench():\n",
    "    features = deepcopy([greenSmall])\n",
    "    for _ in range(60):\n",
    "        ret, frame = cap.read()\n",
    "        handleFrame(frame, features)\n",
    "    \n",
    "%lprun -r -f do_binary_search bench()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
