{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy-quaternion in /usr/local/lib/python2.7/dist-packages\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install numpy-quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quaternion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "from camera_calibration_parsers import readCalibration\n",
    "import image_geometry\n",
    "\n",
    "from tf import transformations\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "\n",
    "import rospy\n",
    "from geometry_msgs.msg import PoseStamped, Pose, Vector3, Quaternion\n",
    "from std_msgs.msg import Header\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from client_mk1.fast_image import Image\n",
    "from client_mk1.color import Color\n",
    "from client_mk1.feat_2d import Circle2D\n",
    "from client_mk1.searchers import do_linear_search, do_binary_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -rospy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rospy.init_node('fast_localization_client')\n",
    "try:\n",
    "    pose_pub.unregister()\n",
    "except:\n",
    "    pass\n",
    "pose_pub = rospy.Publisher('/pose', PoseStamped, queue_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Useful resources\n",
    "\n",
    "[OpenCV tutorial](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html#playing-video-from-file)\n",
    "\n",
    "![](http://wiki.ros.org/image_pipeline/CameraInfo?action=AttachFile&do=get&target=CameraCoords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load camera configuration info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_, calibration = readCalibration(\"../calibration/stabilized_pixel.yaml\")\n",
    "camera = image_geometry.PinholeCameraModel()\n",
    "camera.fromCameraInfo(calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define types for 3D features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Sphere3D(object):\n",
    "    \"\"\"\n",
    "    Sphere3D represents a sphere known to exist in 3D map-space.\n",
    "    \"\"\"\n",
    "    def __init__(self, center, radius, colorRange):\n",
    "        self.center = np.array(center)\n",
    "        self.radius = radius\n",
    "        self.color = colorRange\n",
    "\n",
    "        # TODO: this should be a scalar with more reasonable behavior\n",
    "        self.confidence = True\n",
    "        \n",
    "    def project(self, pos, orientation):\n",
    "        \"\"\"\n",
    "        Returns the coordinates of the given point in the camera image\n",
    "        \"\"\"\n",
    "        relative_center = self.center - pos\n",
    "        relative_center = np.dot(np.transpose(orientation), relative_center)\n",
    "        \n",
    "        center2D = camera.project3dToPixel(relative_center)\n",
    "        x, y, w = relative_center\n",
    "        radius2D = camera.fx() * self.radius / w\n",
    "        \n",
    "        return Circle2D(center2D, radius2D, self.color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Circle(center=[ 1098.95683619   759.8195455 ], radius=79.1447580925)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = greenSphere\n",
    "s.project(startPos,np.identity(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define hardcoded map for testing tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "green = Color((30, 60, 100), (60, 255, 255))\n",
    "orange = Color((5, 150, 130), (30, 255, 255))\n",
    "blue = Color((100, 70, 100), (140, 255, 255))\n",
    "black = Color((0, 0, 0), (255, 200, 150))\n",
    "\n",
    "# greenCircle = Circle2D((1920/2, 1080/2), 400, green)\n",
    "# orangeCircle = Circle2D((1920/2, 1080/2), 400, orange)\n",
    "\n",
    "greenSmall = Circle2D((1100, 700), 130, green)\n",
    "orangeSmall = Circle2D((600, 700), 130, orange)\n",
    "\n",
    "greenSphere = Sphere3D((.4,.3,0), .106, green)\n",
    "orangeSphere = Sphere3D((-.4,.3,0), .106, orange)\n",
    "blueSphere = Sphere3D((.4,-.3,0), .106, blue)\n",
    "blackSphere = Sphere3D((-.4,-.3,0), .106, black)\n",
    "\n",
    "\n",
    "startPos = np.array([.25, 0, -2.4])\n",
    "startQuat = np.quaternion(1, 0, 0 ,0)\n",
    "\n",
    "\n",
    "greenCircle = greenSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "orangeCircle = orangeSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "blueCircle = blueSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "blackCircle = blackSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Find 3D poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def packStateVector(pos, quat):\n",
    "    return np.array(tuple(pos)+tuple(quaternion.as_float_array(quat).ravel()))\n",
    "\n",
    "def unpackStateVector(state):\n",
    "    position = np.array(state[:3])\n",
    "    quat = np.quaternion(*state[3:])\n",
    "    return position, quat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.63450900e-02,  -1.88756500e-02,  -2.86295623e+00,\n",
       "         9.99615505e-01,  -1.00498077e-02,   5.05565336e-02,\n",
       "        -2.13947738e-03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packStateVector([-0.07634509, -0.01887565, -2.86295623],np.quaternion(0.999615505058199, -0.0100498077476995, 0.0505565336078942, -0.00213947738153386))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getDistFunc(spheres, foundCircles):\n",
    "    assert len(spheres) == len(foundCircles)\n",
    "    def distFunc(state):\n",
    "        position, quat = unpackStateVector(state)\n",
    "        \"\"\"\n",
    "        Takes a list of 7 numbers. The first three represent translational \n",
    "        position, and the last four form a rotation quaternion.\n",
    "        Returns a list of error values.\n",
    "        \"\"\"\n",
    "        matrix = quaternion.as_rotation_matrix(quat)\n",
    "        \n",
    "        errors = [c.distance(s.project(position, matrix).center)\n",
    "         for s, c in zip(spheres, foundCircles)\n",
    "                 if c.confidence == True]\n",
    "        \n",
    "        # Note that scipy leastsq requires sufficient number of outputs,\n",
    "        # hacked here by feeding extra '0's\n",
    "        return errors + [quat.norm() - 1] + [0]*5\n",
    "        \n",
    "        \n",
    "    return distFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "quat = np.quaternion(1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59.828640420506638, 115.12375656779729, 0.0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDistFunc([greenSphere, orangeSphere], [greenSmall, orangeSmall]\n",
    "           )(packStateVector(startPos, startQuat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: massive speed boosts should come from computing\n",
    "# the Jacobian more sensibly\n",
    "def findPose(spheres, circles, pos, quat, verbose=False):\n",
    "    p,cov,infodict,mesg,ier = optimize.leastsq(\n",
    "        getDistFunc(spheres, circles),\n",
    "        packStateVector(pos, quat),\n",
    "        xtol=1e-2,\n",
    "        full_output=1)\n",
    "    if verbose:\n",
    "        print '{} evaluations needed, final error {}'.format(infodict['nfev'], infodict['fvec'])\n",
    "    return unpackStateVector(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 evaluations needed, final error [  1.57519085e+01   3.83802228e+00   4.08302228e-05   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.30242496, -0.03330195, -2.74186211]),\n",
       " quaternion(0.99972272345712, -0.0162327489347156, -0.0171679951867904, 0.00608803988037122))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findPose([greenSphere, orangeSphere], [greenSmall, orangeSmall],\n",
    "         startPos, startQuat, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def publish_pose(pos, quat):\n",
    "    pose_pub.publish(PoseStamped(\n",
    "        header=Header(frame_id='map'),\n",
    "        pose=Pose(\n",
    "            position=Vector3(*pos), \n",
    "            orientation=Quaternion(*(quaternion.as_float_array(quat).flatten())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Capture and handle video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FILE = '../test_data/smooth_1.mp4'\n",
    "cv2.namedWindow('raw_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 evaluations needed, final error [ 17.97863322   6.6726412   18.09802659  18.24085954   1.89933321   0.           0.\n",
      "   0.           0.           0.        ]\n",
      "9.2ms reading and drawing image, 13.5ms (73fps) processing, 148 pixels accessed\n",
      "\n",
      "End of video file reached\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def handleFrame(frame, features, verbose=False):\n",
    "    image = Image(frame)\n",
    "\n",
    "    for f in features:\n",
    "        f.refine(image, verbose=verbose)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def main():\n",
    "    pos = startPos\n",
    "    quat = startQuat\n",
    "    spheres = deepcopy([greenSphere, orangeSphere, blueSphere, blackSphere])\n",
    "    i=0\n",
    "    while cap.isOpened():\n",
    "        verbose = i%50 == 0\n",
    "        if verbose:\n",
    "            clear_output()\n",
    "        i += 1\n",
    "        \n",
    "        startTime = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        readTime = time.time()\n",
    "\n",
    "        if frame is None or len(frame) <= 0:\n",
    "            print \"End of video file reached\"\n",
    "            break\n",
    "\n",
    "        # Do work here\n",
    "        features = [sphere.project(pos, quaternion.as_rotation_matrix(quat))\n",
    "                   for sphere in spheres]\n",
    "        \n",
    "        image = handleFrame(frame, features, verbose=verbose)\n",
    "        \n",
    "        pos, quat = findPose(spheres, features, pos, quat, verbose=verbose)\n",
    "            \n",
    "        finishTime = time.time()\n",
    "        \n",
    "        publish_pose(pos, quat)\n",
    "\n",
    "        for f in features:\n",
    "            f.draw(frame)\n",
    "            \n",
    "        image.draw(frame)\n",
    "        scaled = cv2.resize(frame, dsize=None, fx=0.5, fy=0.5)\n",
    "        cv2.imshow('raw_frame', scaled)\n",
    "        \n",
    "        drawnTime = time.time()\n",
    "\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        if verbose:\n",
    "            processingTime = (finishTime-readTime)\n",
    "            print \"{0:.1f}ms reading and drawing image, {1:.1f}ms ({3}fps) processing, {2} pixels accessed\\n\".format(\n",
    "                (readTime-startTime + drawnTime-finishTime)*1000, \n",
    "                processingTime*1000, \n",
    "                len(image.pixelsAccessed),\n",
    "                int(1/processingTime))\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Circle(center=[ 1098.95683619   309.4255025 ], radius=79.1447580925)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blueCircle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Profile things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def bench():\n",
    "    features = deepcopy([greenSmall])\n",
    "    for _ in range(60):\n",
    "        ret, frame = cap.read()\n",
    "        handleFrame(frame, features)\n",
    "    \n",
    "%lprun -r -f doBinarySearch bench()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
