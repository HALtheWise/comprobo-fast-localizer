{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install numpy-quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/quaternion/numba_wrapper.py:29: UserWarning: \n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Could not import from either numbapro or numba.\n",
      "This means that the code will run MUCH more slowly.\n",
      "You probably REALLY want to install numba / numbapro.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "  warnings.warn(warning_text)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import quaternion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "from camera_calibration_parsers import readCalibration\n",
    "import image_geometry\n",
    "\n",
    "from tf import transformations\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from client_mk1.fast_image import Image\n",
    "from client_mk1.color import Color\n",
    "from client_mk1.feat_2d import Circle2D\n",
    "from client_mk1.searchers import do_linear_search, do_binary_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Useful resources\n",
    "\n",
    "[OpenCV tutorial](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html#playing-video-from-file)\n",
    "\n",
    "![](http://wiki.ros.org/image_pipeline/CameraInfo?action=AttachFile&do=get&target=CameraCoords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load camera configuration info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_, calibration = readCalibration(\"../calibration/stabilized_pixel.yaml\")\n",
    "camera = image_geometry.PinholeCameraModel()\n",
    "camera.fromCameraInfo(calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define types for 3D features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Sphere3D(object):\n",
    "    \"\"\"\n",
    "    Sphere3D represents a sphere known to exist in 3D map-space.\n",
    "    \"\"\"\n",
    "    def __init__(self, center, radius, colorRange):\n",
    "        self.center = np.array(center)\n",
    "        self.radius = radius\n",
    "        self.color = colorRange\n",
    "\n",
    "        # TODO: this should be a scalar with more reasonable behavior\n",
    "        self.confidence = True\n",
    "        \n",
    "    def project(self, pos, orientation):\n",
    "        \"\"\"\n",
    "        Returns the coordinates of the given point in the camera image\n",
    "        \"\"\"\n",
    "        relative_center = self.center - pos\n",
    "        relative_center = np.dot(np.transpose(orientation), relative_center)\n",
    "        \n",
    "        center2D = camera.project3dToPixel(relative_center)\n",
    "        x, y, w = relative_center\n",
    "        radius2D = camera.fx() * self.radius / w\n",
    "        \n",
    "        return Circle2D(center2D, radius2D, self.color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'greenSphere' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-550ab1d4aa89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreenSphere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartPos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'greenSphere' is not defined"
     ]
    }
   ],
   "source": [
    "s = greenSphere\n",
    "s.project(startPos,np.identity(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define hardcoded map for testing tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "green = Color((30, 60, 100), (60, 255, 255))\n",
    "orange = Color((5, 150, 130), (30, 255, 255))\n",
    "blue = Color((100, 70, 100), (140, 255, 255))\n",
    "black = Color((0, 0, 0), (255, 255, 100))\n",
    "\n",
    "greenCircle = Circle2D((1920/2, 1080/2), 400, green)\n",
    "orangeCircle = Circle2D((1920/2, 1080/2), 400, orange)\n",
    "\n",
    "greenSmall = Circle2D((1100, 700), 130, green)\n",
    "orangeSmall = Circle2D((600, 700), 130, orange)\n",
    "\n",
    "greenSphere = Sphere3D((.4,.3,0), .106, green)\n",
    "orangeSphere = Sphere3D((-.4,.3,0), .106, orange)\n",
    "blueSphere = Sphere3D((.4,-.3,0), .106, blue)\n",
    "blackSphere = Sphere3D((-.4,-.3,0), .106, black)\n",
    "\n",
    "\n",
    "startPos = np.array([0, 0, -2])\n",
    "startQuat = np.quaternion(1, 0, 0 ,0)\n",
    "\n",
    "\n",
    "blueCircle = blueSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))\n",
    "blackCircle = blackSphere.project(startPos, quaternion.as_rotation_matrix(startQuat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Find 3D poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def packStateVector(pos, quat):\n",
    "    return np.array(tuple(pos)+tuple(quaternion.as_float_array(quat).ravel()))\n",
    "\n",
    "def unpackStateVector(state):\n",
    "    position = np.array(state[:3])\n",
    "    quat = np.quaternion(*state[3:])\n",
    "    return position, quat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.63450900e-02,  -1.88756500e-02,  -2.86295623e+00,\n",
       "         9.99615505e-01,  -1.00498077e-02,   5.05565336e-02,\n",
       "        -2.13947738e-03])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packStateVector([-0.07634509, -0.01887565, -2.86295623],np.quaternion(0.999615505058199, -0.0100498077476995, 0.0505565336078942, -0.00213947738153386))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getDistFunc(spheres, foundCircles):\n",
    "    assert len(spheres) == len(foundCircles)\n",
    "    def distFunc(state):\n",
    "        position, quat = unpackStateVector(state)\n",
    "        \"\"\"\n",
    "        Takes a list of 7 numbers. The first three represent translational \n",
    "        position, and the last four form a rotation quaternion.\n",
    "        Returns a list of error values.\n",
    "        \"\"\"\n",
    "        matrix = quaternion.as_rotation_matrix(quat)\n",
    "        \n",
    "        errors = [c.distance(s.project(position, matrix).center)\n",
    "         for s, c in zip(spheres, foundCircles)]\n",
    "        \n",
    "        # Note that scipy leastsq requires sufficient number of outputs,\n",
    "        # hacked here by feeding extra '0's\n",
    "        return errors + [quat.norm() - 1] + [0]*4\n",
    "        \n",
    "        \n",
    "    return distFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "quat = np.quaternion(1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[266.15972648017203, 107.70329614269008, 0.0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDistFunc([greenSphere, orangeSphere], [greenSmall, orangeSmall]\n",
    "           )(packStateVector(startPos, startQuat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: massive speed boosts should come from computing\n",
    "# the Jacobian more sensibly\n",
    "p,cov,infodict,mesg,ier = optimize.leastsq(\n",
    "    getDistFunc([greenSphere, orangeSphere], [greenSmall, orangeSmall]),\n",
    "    packStateVector(startPos, startQuat),\n",
    "    xtol=1e-2,\n",
    "    full_output=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 evaluations needed, final error [ 266.15972648  107.70329614    0.            0.            0.            0.\n",
      "    0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0., -2.]), quaternion(1, 0, 0, 0))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print '{} evaluations needed, final error {}'.format(infodict['nfev'], infodict['fvec'])\n",
    "unpackStateVector(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Capture and handle video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FILE = '../test_data/smooth_1.mp4'\n",
    "cv2.namedWindow('raw_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9ms reading and drawing image, 6.2ms (161fps) processing, 148 pixels accessed\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-741a79623b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                 int(1/processingTime))\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-741a79623b50>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Do work here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandleFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfinishTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-741a79623b50>\u001b[0m in \u001b[0;36mhandleFrame\u001b[0;34m(frame, features, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mount/btrfs/btrHome/git/fast_localizer/exploration/client_mk1/feat_2d.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, image, verbose, searchRange)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         topPoint = do_binary_search(image, self.color,\n\u001b[0;32m---> 75\u001b[0;31m                                     self.center, self.center - maxDist * up)\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mount/btrfs/btrHome/git/fast_localizer/exploration/client_mk1/searchers.pyc\u001b[0m in \u001b[0;36mdo_binary_search\u001b[0;34m(image, color, start, end, numSteps, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetHSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mount/btrfs/btrHome/git/fast_localizer/exploration/client_mk1/fast_image.pyc\u001b[0m in \u001b[0;36mgetHSV\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mhsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def handleFrame(frame, features, verbose=False):\n",
    "    image = Image(frame)\n",
    "\n",
    "    for f in features:\n",
    "        f.refine(image, verbose=verbose)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def main():\n",
    "    features = deepcopy([greenSmall, orangeSmall, blueCircle, blackCircle])\n",
    "    i=0\n",
    "    while cap.isOpened():\n",
    "        verbose = i%50 == 0\n",
    "        if verbose:\n",
    "            clear_output()\n",
    "        i += 1\n",
    "        \n",
    "        startTime = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        readTime = time.time()\n",
    "\n",
    "        if frame is None or len(frame) <= 0:\n",
    "            print \"End of video file reached\"\n",
    "            break\n",
    "\n",
    "        # Do work here\n",
    "        image = handleFrame(frame, features, verbose=verbose)\n",
    "        \n",
    "        finishTime = time.time()\n",
    "\n",
    "        for f in features:\n",
    "            f.draw(frame)\n",
    "            \n",
    "        image.draw(frame)\n",
    "        scaled = cv2.resize(frame, dsize=None, fx=0.5, fy=0.5)\n",
    "        cv2.imshow('raw_frame', scaled)\n",
    "        \n",
    "        drawnTime = time.time()\n",
    "\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        if verbose:\n",
    "            processingTime = (finishTime-readTime)\n",
    "            print \"{0:.1f}ms reading and drawing image, {1:.1f}ms ({3}fps) processing, {2} pixels accessed\\n\".format(\n",
    "                (readTime-startTime + drawnTime-finishTime)*1000, \n",
    "                processingTime*1000, \n",
    "                len(image.pixelsAccessed),\n",
    "                int(1/processingTime))\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Circle(center=[ 1345.3508944   264.3860982], radius=94.973709711)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blueCircle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Profile things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(FILE)\n",
    "\n",
    "def bench():\n",
    "    features = deepcopy([greenSmall])\n",
    "    for _ in range(60):\n",
    "        ret, frame = cap.read()\n",
    "        handleFrame(frame, features)\n",
    "    \n",
    "%lprun -r -f doBinarySearch bench()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
